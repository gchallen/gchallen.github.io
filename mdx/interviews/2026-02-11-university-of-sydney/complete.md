# Geoffrey Challen — University of Sydney Application Materials

This document contains all text content from Geoffrey Challen's application to the Associate Professor position in the Sydney Horizon Educators program at the University of Sydney's School of Computer Science. It is provided as a single file suitable for use with AI tools.

---

## Application Letter

Geoffrey Challen
geoffrey.challen@gmail.com
https://www.geoffreychallen.com/

26 November 2025

Dear Members of the Search Committee:

I am writing to apply for the Associate Professor position in the Sydney Horizon Educators program at the University of Sydney's School of Computer Science. The Sydney Horizon Educators program's emphasis on educational leadership, scholarship, and innovation represents an ideal alignment with my expertise and aspirations. The program is also well-timed, with rapid advances in artificial intelligence opening up both new challenges and remarkable opportunities for higher education. I should mention that, while I currently hold the rank of Teaching Professor, I am applying for the advertised opening at the Associate Professor level, recognizing that academic rank structures differ between institutions and that this position offers opportunities for educational leadership that align with my career goals.

Over eight years teaching one of the world's largest and most innovative introductory computer science courses, I have pursued a singular professional goal: to teach computer science to everyone who wants to learn and to inspire them to use their technical superpowers to improve our world. My approach combines pedagogical innovation and software engineering to create interactive and engaging environments that support learning at scale.

While at Illinois, I have taught introductory computer science to over 16,000 students. When I began teaching CS 124 in Fall 2017, it was taught in Java to 700 students, 50% earned A-range grades, and 5% failed. In Fall 2024, we offered both Kotlin and Java, 1,200 students enrolled, 80% earned A-range grades, and only 2.5% failed. We have reduced performance gaps between genders, between majors and non-majors, and between students with less and more prior experience. But not through a loss of rigor. In Fall 2017, students only wrote code once in a proctored environment: on the paper final exam. In Fall 2024, CS 124 students completed multiple autograded programming challenges each week in our computer-based testing facility, with quiz performance comprising the majority of their course grade. We cover more material now than we did in 2017, and more than introductory computing courses at peer institutions. Over this interval, overall performance has improved, even as expectations and the amount of proctored assessment have risen.

Improved student performance in CS 124 is the result of innovative changes to course design and delivery. One of the most important changes is our use of frequent small assessment. Infrequent high-stakes assessments—such as heavily-weighted exams—cause students to get behind, cram to catch up, and forget immediately after the big test. In contrast, frequent small assessments cause students to keep up, study, and learn. CS 124 has entirely abandoned high-stakes assessment: we give no midterm or final. Instead, students complete weekly proctored computer-based quizzes, each comprising several autograded programming challenges and multiple-choice questions. Frequent small assessment provides immediate feedback to both students and staff, enabling early intervention for those who are struggling while reducing stress through flexible policies like dropped scores and retakes.

Our use of frequent small assessment is greatly supported by Illinois's computer-based testing facility. This facility—already a remarkable innovation—is poised to become even more valuable as we confront the challenges of AI. Unlike instructors who are returning to paper or oral examination, I can still assess coding in an authentic environment. I can now both teach students to collaborate with coding agents and ensure they can complete coding tasks unaided. I would love to help establish a similar facility at the University of Sydney.

A second core educational innovation that has supported student success in CS 124 is our move from lectures to our current tutorial model. As the pandemic began, it became clear to me that remote lecturing was even less effective than in-person lecturing. In response, I completely restructured our materials into a series of interactive daily lessons. Each lesson combines text, video, runnable code examples, coding and debugging exercises, and interactive walkthroughs—a novel format that supports asynchronous live coding demonstrations. Compared to lectures, which often promote passivity, our daily lessons encourage active, self-directed learning. Students move at their own pace, with staff available on our online tutoring site throughout the day to help them whenever they get stuck.

I have also contributed to curricular and program development outside of my core teaching responsibilities. I led a team of colleagues that redesigned our early core programming curriculum, revamping a CS2 course that was creating issues with equity and downstream preparation. Our changes facilitated long-stalled improvements to neighboring courses in the sequence, and have proven effective over the past several years. I created a new reading and discussion seminar on the relationship between society and technology, which I have now taught for several semesters. Inspired by the ongoing revolution in AI, I am designing a new course on using and understanding AI, which I will pilot in Spring 2026.

While my current role does not focus on academic research, the novel tools and technologies that I have created represent research and development. Several have been published at leading computer science education venues, including SIGCSE, CSEEE&T, and ASE. Working with collaborators at Illinois, I have led research studies exploring how students develop preferences between instructors, the effectiveness of split deadline policies in improving student performance in large courses, and how to effectively author multiple variants of questions to support asynchronous assessment. I have also published papers on innovative CS 124 tools, such as our programming question authoring system.

My engagement with research and scholarship starts with building and deploying novel tools and ideas to support students in my own courses. Through ongoing data collection and discussion with senior course staff, we investigate the efficacy of changes, producing a cycle by which my course is continuously evolving and improving. Significant improvements and results are shared in a variety of ways: through my writing, online engagement with other instructors, and academic publication. I also maintain learncs.online, a public version of my CS1 course materials that allows anyone to use and benefit from course-specific innovations and materials.

Before I began as teaching faculty at Illinois, I spent six years at the University at Buffalo as a research-focused faculty member. I led a mobile systems research group, mentored three excellent doctoral students, supervised both graduate and undergraduate students, co-authored many papers, created innovative courses, and spearheaded a holistic curricular overhaul. During that time, I also raised almost $3M in external funding, including the prestigious NSF CAREER award. Since arriving at Illinois, my grant writing has been limited to internal awards, but I do have experience obtaining competitive external funding.

I have held various service roles at Illinois. When possible, I have tried to approach them in ways that produce lasting impact. As the first teaching-track faculty to chair our teaching faculty search, I redesigned the interview process, replacing an unhelpful teaching demonstration with an open-ended presentation on effective pedagogy. This change has proven highly successful. It reduces the inappropriate emphasis on classroom teaching and allows candidates to present their holistic approach to instruction: assessment, materials, scaling, equity, use of technology, and so on. These well-attended talks also expose faculty to new pedagogical ideas and techniques. I have also served on the university's General Education Board and engineering college's Curriculum Review Committee.

I maintain networks connecting me with teaching faculty at many other institutions. I helped start the Illinois Computer Science Summer Teaching Workshop, an event that brings together educators to discuss best practices, propose new directions, and challenge the status quo. I have authored essays on my website on a variety of teaching-related topics. I also participate in a large online community of practice, engaging in conversations about computer science education with colleagues from across the country and around the world. I particularly enjoy mentoring junior teaching faculty colleagues. Over my time at Illinois, I have also supervised over two thousand CS 124 course staff.

While my current position does not leave much time for pursuing external partnerships, I have had some success in seeing learncs.online used outside of Illinois: by faculty using the content to support their own courses, by outreach programs for diverse high school students, and by teacher training courses. I am particularly excited that, in Fall 2025, we are piloting our first community college collaboration with Wilbur Wright College, and we plan to expand on this initial effort in future semesters. I maintain connections with EdStem and PrairieLearn, two leading educational technology companies.

The Sydney Horizon Educators program represents an exceptional opportunity to advance educational innovation at scale while contributing to pedagogical scholarship. The program's 70/20/10 teaching/research/service split closely aligns with both my current appointment structure (60/20/20) and my professional priorities. I am particularly excited by the prospect of managing high-enrollment units at Sydney, bringing my experience transforming large courses to a new institutional context. The access to education-focused grants would support continued development of novel educational technologies and research on student learning at scale. I am eager to contribute to Sydney's mission of preparing students for their future careers through outstanding educational delivery, curriculum innovation, and scholarship that advances computer science education, particularly at the dawn of the AI era. I would welcome the opportunity to discuss how my experience and vision align with the School of Computer Science's goals for this position.

Best,

Geoffrey Challen

---

## Video Transcript

Hi, I'm Geoff Challen. I teach computer science at the University of Illinois. In this video, I'm going to show you the interactive walkthrough component that I created to support student success in CS1 and to teach computer science to thousands of students. To do this, I'm going to demo it on learncs.online. This website is the publicly available version of the same course materials that we use at the University of Illinois. But it's freely available, so you're welcome to create an account, log on, and follow along.

The format of these materials goes back to the pandemic. Like other instructors, I was challenged with the task of teaching a remote population during the pandemic, and I chose to use that as an opportunity to innovate, creating a new format for the course materials, a format that has proven so successful that we still use it today, even though the pandemic is over. We saw student success rates rise, and today about 80% of the students in my course earn A-range grades, even after a lot of rigorous testing. So how does this work? Let me walk you through the process to give some context for the interactive walkthroughs themselves.

My course does not use a lecture model of instruction. Instead, each day students complete an interactive lesson. Those lessons start with students writing hello world. We start with students that have never written a line of code before. We teach them day by day the basics of imperative programming. Then we get into some objects, baby data structures, and recursion by the end of the class. And by the time they finish, students are not only able to write more complex programs, but they're able to complete most of the implementation of a simple Android application.

Let's take a look at one of these lessons. The learncs.online lessons are similar to the ones that we use in my class, and they comprise a variety of interactive components. My goal is to make these as engaging as possible. I want students' hands to stay close to the keyboard. I don't want them to zone out or get passive. I want them to have opportunities to interact with the content throughout the lesson. So for example, every piece of code on the website can be edited and run in the browser. So I can make changes and I can experiment. That's one way that students learn. Here's another example of a playground, as we call them. And then here's our first example of an interactive walkthrough. So let me go ahead and show you how this works. I'm going to use Colleen Lewis's explanation here. I'm going to jump ahead a little bit and play it from about a minute in.

And so what you can see is that we're listening to Colleen, but we're also watching her manipulate the code. This may look a lot like a video, and that was my inspiration. But it solves one of my core frustrations with explanatory coding videos. And this is something that I realized when I started to click on them, because I was trying to experiment with the code, forgetting that that valuable code, that valuable data for instructional use had been destroyed and converted to pixels. In the interactive walkthroughs the code is preserved. So at any point a student can pause the walkthrough and they can take over and they can make the changes that they want to make. We have some check style layers that we need to fix here, for example, and they can try new things.

And so what we have is the best of a video explanation but also the ability for students to always interact with the code and keep the materials engaging. I'm going to come back and show you how to record one of these, but just let me finish looking at the rest of the lesson. So we also use video if there's things that we can't explain through code, but the interactive walkthroughs are really the workhorse and foundation of the explanatory content on the site. Here's another one. This one's about four minutes. Here's a longer one. It's about eight minutes. We try to keep these to about five minutes long, and we try to really focus them on a single topic. Towards the end of the lesson or throughout we also have a lot of different assessment type components. That's not my focus right now, but we have code writing challenges like this one, we have debugging challenges where students have broken code that they need to fix, and then we also have a new test writing challenge where students are challenged to write tests for an existing problem and we evaluate how accurate their tests are. That's pretty exciting.

So let's go back to the interactive walkthroughs and I want to show you how these are created. To do that, I'm going to log in with an instructor account. And now you'll be able to see that there's this record button here. And the recording of interactive walkthroughs is done entirely in situ. It's done in the context of the page and the rest of the materials. So you can see, I can see what led into it. I can see what follows it. I can see the whole context of this walkthrough to help understand what is its purpose, and what role is it playing within the context of the lesson. When I'm ready to create my own explanation, I can hit the record button and then I just start talking and typing. If I want to run the code, I can do that. We also have a version of this that's connected with our homework autograder, so we can record solution explanations as well. And off I go. So I can make changes. I can show students how to do things with the code. And in general, I talk and I type until I'm finished with my explanation. At that point, I'm going to go over here and stop the recording. If I want to run their code, I can do that. And you can hear now that I'm previewing my explanation, which is a default setting so that we make sure that we review stuff before we upload it. If I'm happy with it, I hit the upload button and it appears on the site immediately.

I wanted this to be as seamless as possible for a couple of reasons. First, for me, obviously, so it's easy for me to make changes to the materials and add explanations. But part of my goal with these was to create a community of instructors and to make it easier for my staff to contribute to the course materials. And here's an example. So you'll see there's an explanation from me. There is one from Colleen Lewis, who's a colleague of mine at the University of Illinois, who was a co-instructor for the course in 2021, and there are two course staff members who have also recorded their own explanations. This is very easy to do, as I just said, and what this does is it diversifies the voice with which the course speaks.

I'm a white, straight, cisgender frisbee-playing computer scientist. So I know that I check a lot of stereotype boxes when it comes to what students might think a computer scientist is quote-unquote supposed to look like. And so I'm very conscious of that. I teach a diverse population of students, and I want to make sure that they can see themselves succeeding in computer science. And I think I worry sometimes that too much of watching or listening to people with certain identity attributes ends up making people think maybe that they aren't going to be able to succeed. So I wanted a way to invite other voices into the course to make it possible for many different people to contribute to the course materials. That's what's happened. We now have contributions from hundreds of course staff members, four instructors, two of them at external institutions now, and then hundreds and hundreds of current and former staff members. Many of them have made a small number of contributions, which is fine. That's one of the nice things about this. You don't have to rerecord a whole big chunk of content. You can just find one explanation that maybe you like or maybe you don't like the existing explanations and you think you can improve on. Spend a few minutes coming up with a plan, record it, and you're done. And so over time, we've amassed a large corpus of these. As you can see here, we've got over 3,000 explanations from over 300 instructors, totaling about 201 hours of live coding walkthroughs.

We use these. These generate data as they run about what students are watching, and we use that data in a couple of ways. In my class, we create accountability by linking completion of the walkthroughs to student performance. So this is the grades page that my students have access to where they can see how they're doing in the class. And on this, for each lesson, we also have information about walkthrough completion. This student watched most of the walkthroughs. They also did very well in the course. But when students are not doing well, frequently we can use this data to be able to help them understand, hey, if you want to succeed in the class, one thing you might want to try is paying more attention to the materials and spending more time there.

We've also used this data to do studies about student behavior. So this was published at SIGCSE last year. It's joint work with Luc Paquette, a colleague of mine at the School of Education and his student Rachel Zhao, where we use this data to look at how students develop preferences when there are multiple instructors who are both involved with the same course. I will refer you to the details in the paper, but there were some quite interesting insights that came out of this analysis.

So what next? Where do we go from here? I would love to bring this innovation, this specific innovation, but also my deep interest in technological innovation to support education to the University of Sydney. And I think that this type of technology would be able to support students in a wide variety of courses. I think there's opportunities to expand this outside of just introductory computer science to different types of textual-based explanation. And of course there are so many exciting new opportunities with AI as it transforms computer science and education. Could we use AI to generate custom walkthroughs for students who are struggling based on their knowledge gaps? We identify a knowledge gap using an assessment, then we generate a custom walkthrough to target the very things that the student is having a hard time understanding, and of course the AI can generate multiple of these if needed. So I would be incredibly excited to bring not only this specific technology but my continued interest in technological innovation to support the University of Sydney.

---

## Curriculum Vitae

Geoffrey Challen (ne Werner-Allen)

My professional goal is to teach computer science to as many people as possible, and to inspire them to use their skills to change the world for the better.

Department of Computer Science
University of Illinois
Thomas M. Siebel Center for Computer Science
201 North Goodwin Avenue, Urbana, IL, 61801-2302

|                                  |                                            |
| -------------------------------- | ------------------------------------------ |
| Email:                           | challen@illinois.edu                       |
| Phone:                           | 716.464.2749                               |
| Website:                         | https://geoffreychallen.com                |
| Public Course Materials:         | https://learncs.online                     |
| Primary Course Website:          | https://cs124.org                          |
| CV:                              | https://geoffreychallen.com/CV             |
| Statements:                      | https://www.geoffreychallen.com/statements |
| Previous Research Group Website: | https://bluegroup.systems                  |
| Google Scholar Profile:          | https://geoffreychallen.com/scholar        |

**My online CV at geoffreychallen.com/CV is always more up-to-date than any paper copy.**

### Appointments and Preparation

I'm a Teaching Professor at the University of Illinois. My appointment is 60% teaching, 20% scholarship, and 20% service. My focus is teaching at scale.

At this particular moment in computing history, what we need is not more computer _power_—we need more computer _people_. My goal is to create courses that excite, train, and retain these new computer scientists. I focus on instructional approaches that can scale to large numbers of students using limited human resources. I apply my own skills as a computer scientist to this task, by building novel tools and systems that create interactive and engaging learning environments.

My CS1 course currently enrolls over 2000 students per year. Since I began teaching the course in Fall 2017, enrollment has doubled, drop rates have fallen, success rates have increased, student performance in later courses has improved, a gender performance gap has disappeared, students are practicing and learning more, the amount of content covered has increased, we have introduced Kotlin as a language option alongside Java, and hundreds of staff members have made contributions that help diversify the voice with which the course speaks.

#### Previous Position

From 2011–2017 I worked in mobile systems as a research professor at the University at Buffalo. My research group designed, built, and evaluated novel computer systems. We focused on smartphones, since they represent the most pervasive and powerful distributed system ever deployed. My previous group's website (https://www.bluegroup.systems) is the best source of information about my prior research.

#### Academic Appointments

- 2024–: Teaching Professor, University of Illinois
- 2017–2024: Associate Teaching Professor, University of Illinois
- 2011–2017: Assistant Professor, University at Buffalo

#### Professional Preparation

- 2010–2011, Postdoctoral Associate, Massachusetts Institute of Technology (MIT). Supervised by Hari Balakrishnan.
- 2010, Ph.D, Computer Science, Harvard University. Dissertation: "Data Fidelity and Resource Management for Data-Rich Sensor Networks". Advised by Matt Welsh.
- 2003, AB, Physics, Harvard University.

### Teaching

Over 21 terms at Illinois I have taught a total of 16,107 students. I have focused my efforts on expanding and improving our CS1 course for majors and students with deep interest in the material—previously numbered CS 125 and now CS 124.

#### Overview

Only primary teaching assignments are listed.

- **Fall 2024–:** "CS 199 SOC: Technology and Society" (New Course) (University of Illinois)
- **Fall 2021–:** "CS 124: Introduction to Computer Science I" (Renumbered Course) (University of Illinois)
- **Fall 2017–Summer 2021:** "CS 125: Introduction to Computer Science" (University of Illinois)
- **Fall 2016:** "CS 199: How the Internet Works" (New Course) (University at Buffalo)
- **Spring 2011–Spring 2017:** "CS 421: Introduction to Operating Systems" (University at Buffalo)

#### Course and Curricular Innovations and Improvements

- **2025:** Started work on several integrations of AI into course infrastructure, systems, and materials
- **2025:** Began teaching effective use of coding agents on the course larger Android programming project
- **2025:** Enhanced online proctoring interface to support remote students
- **2025:** Added quiz retake opportunities, allowing students additional chances to demonstrate mastery
- **2025:** Completed major database reorganization for improved system performance and scalability
- **2024:** Deployed autogenerated testing exercises, providing students with practice writing test suites
- **2024:** Integrated code quality instruction and automated feedback into daily lesson content
- **2024:** Launched coaching program to proactively contact students in need of support and offer individual course strategy sessions
- **2024:** Deployed Redis-based caching system for better platform performance at scale
- **2024:** Expanded compilation infrastructure to support mixed Java/Kotlin projects
- **2023:** Introduced mutation testing framework for automated debugging challenge generation
- **2023:** Began work adding support for automated test evaluation to our homework autograder
- **2023:** Added profiles of diverse computer scientists to our daily lessons as part of a CS People series
- **2022:** Integrated debugging exercises throughout our CS1 daily lessons
- **2022:** Upgraded our online quiz tool to add improved quiz security features and provide more practice content
- **2022:** Made most of our highly-successful CS1 materials publicly available at https://www.learncs.online/
- **2022:** Established a successful course staff mentorship program
- **2022:** Created a practice page providing students with access to our entire library of over 700 small programming problems
- **2021:** Officially introduced Kotlin as a new language option for CS 124, with parallel lessons, content, and assessments running alongside our existing Java materials
- **2021:** Created a new tool for generating small debugging challenges, allowing successful student submissions to existing homework problems to generate large numbers of new, interesting, and autogradeable questions
- **2021:** Created a series of introductory Kotlin lessons to complement and eventually run side-by-side with our existing Java lessons
- **2020:** Developed a new interactive walkthrough format for deploying live coding explanations and soliciting contributions from course staff
- **2020:** Created a new online quiz system to support remote Zoom proctoring
- **2020:** Restructured CS 125 to support asynchronous instruction in a daily interactive lesson format
- **2020:** Designed and developed a new framework accelerating the development of small Java programming problems
- **2020:** Created an efficient online help system to support students after CS 125 transitioned online
- **2019:** Authored and deployed the first multi-part Android programming project for CS 125
- **2019:** Deployed CS 125 on local cloud infrastructure providing enhanced scalability and robustness
- **2019:** Developed a new Java and JVM playground backend and toolkit to support interactive programming exercises in CS 125
- **2019:** Reauthored our on-demand Git autograder for larger CS 125 assignments to run on Kubernetes
- **2018:** Began authoring a large and growing library of small Java homework problems to support CS 125
- **2018:** Developed a Java autograder and programming problems for CS 125 quizzes
- **2018:** Created on-demand Git autograder for CS 125 assignments
- **2017:** Created on-demand Subversion autograder for CS 125 assignments
- **2016:** Implemented novel video delivery and tracking systems for internet-class.org, the website supporting a new course on the internet
- **2015–2016:** Developed test161, a new testing framework for operating system assignments using the OS/161 instructional operating system

#### Semester-by-Semester Details

**CS 124: Fall 2025 (In Progress)** — Enrollment: 1100. Integrated effective use of AI coding agents into the larger Android programming project. Began work on several AI integrations into course materials and systems.

**CS 124: Spring 2025** — Enrollment: 700. Enhanced online proctoring interface. Added quiz retake opportunities. Completed major database reorganization.

**CS 124: Fall 2024** — Enrollment: 1294. Deployed autogenerated testing exercises. Integrated code quality instruction. Began coaching program. Deployed Redis-based caching system.

**CS 124: Spring 2024** — Enrollment: 782. Enhanced compilation infrastructure. Modernized platform architecture.

**CS 124: Fall 2023** — Enrollment: 1281. Deployed enhanced mutation testing framework. Continued stability improvements. Enhanced assessment platform.

**CS 124: Spring 2023** — Enrollment: 879. Added CS People series. Began work on autograding test suites. Deployed new code quality analysis features.

**CS 124: Fall 2022** — Enrollment: 1399. Fully incorporated debugging challenges. Completed new quiz security features.

**CS 124: Spring 2022** — Enrollment: 666. Began work on debugging challenges. Released materials publicly at learncs.online. Improved staff mentoring program.

**CS 124: Fall 2021** — Enrollment: 1441. Introduced Kotlin alongside Java. Colleen Lewis joined as co-instructor.

**CS 125: Spring 2021** — Enrollment: 613. Continued improving systems for new course format.

**CS 125: Fall 2020** — Enrollment: 1103. Relaunched course in new asynchronous online daily lesson format. Deployed novel homework autograder. Transitioned to new quizzing and proctoring tool.

**CS 125: Spring 2020** — Enrollment: 380. Transitioned online mid-semester due to COVID-19. Completed first version of online tutoring site.

**CS 125: Fall 2019** — Enrollment: 696. Deployed first Android machine project. Created distributed cloud-native autograder. Migrated to private cloud with Kubernetes.

**CS 125: Spring 2019** — Enrollment: 459. Began work on Jeed. Improved Android programming assignments.

**CS 125: Fall 2018** — Enrollment: 742. Created first set of daily programming exercises. Eliminated high-stakes final exam. Established course tutoring center.

**CS 125: Spring 2018** — Enrollment: 439. Migrated to interactive online materials. Deployed first version of Jeed. Introduced Android programming. Held first CS 125 Project Fair.

**CS 125: Fall 2017** — Enrollment: 698. Updated assignments and infrastructure. Rewrote all assignments with modern build system.

#### University at Buffalo (2011–2016)

During five years at UB I taught a total of 1150 students. Despite being extremely challenging and required for undergraduate computer science majors, my course on computer operating systems was among the most popular in the department.

### Curriculum Development

- **2024:** Designed and deployed "CS 199 SOC: Technology and Society" (University of Illinois).
- **2020–:** Led a team of faculty that proposed and passed a significant revision to the core programming sequence at the University of Illinois.
- **2016–2017:** Led the Curriculum Development Committee which proposed and passed a significant revision to the undergraduate curriculum at the University at Buffalo.
- **2016:** Designed and deployed "CS 199: How the Internet Works" (University at Buffalo).

### Projects

- learncs.online is the public version of the materials developed to support CS 124—my CS1 course at Illinois.
- Interactive walkthroughs are a novel way to deliver live coding demos online while preserving code interactivity. They've also allowed us to create a vibrant and diverse community of instructional voices.
- Questioner is a novel tool allowing us to write programming exercises 10x faster and more accurately than previous approaches.
- Code quality autograding allows us to provide students with automated feedback on not just correctness, but also on multiple aspects of quality.
- Autogenerated debugging exercises provide students with nearly-unlimited debugging practice.
- Autogenerated testing exercises provide students with the chance to practice writing test suites.
- Our online tutoring site efficiently connects students with staff for one-on-one tutoring sessions.
- Jeed, the speedy JVM execution and analysis toolkit, allows running untrusted code in a secure sandbox 1000 times faster than other approaches.

### Publications

- **02/2025:** Yiqiu Zhou, Luc Paquette, and Geoffrey Challen. Investigating the Presence and Development of Student Instructor Preferences in a Large-Scale CS1 Course. In Proceedings of the 56th ACM Technical Symposium on Computer Science Education (SIGCSE 2025).
- **02/2025:** Geoffrey Challen and Ben Nordick. Accelerating Accurate Assignment Authoring Using Solution-Generated Autograders. In Proceedings of the 56th ACM Technical Symposium on Computer Science Education (SIGCSE 2025).
- **03/2024:** Hongxuan Chen, Ang Li, Geoffrey Challen, and Kathryn Cunningham. Implementation of Split Deadlines in a Large CS1 Course. In Proceedings of the 55th ACM Technical Symposium on Computer Science Education (SIGCSE 2024).
- **11/2020:** Liia Butler, Geoffrey Challen, and Tao Xie. Data-Driven Investigation into Variants of Code Writing Questions. In Proceedings of the 32nd IEEE Conference on Software Engineering Education and Training (CSEE&T 2020).
- **11/2019:** Jonathan Osei-Owusu, Angello Astorga, Liia Butler, Tao Xie, and Geoffrey Challen. Grading-based test suite augmentation. In Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering (ASE 2019).

### Presentations

- **February 27, 2025**: SIGCSE 2025: Accelerating Accurate Assignment Authoring Using Solution-Generated Autograders
- **February 27, 2025**: SIGCSE 2025: Investigating the Presence and Development of Student Instructor Preferences in a Large-Scale CS1 Course
- **March 21, 2024**: SIGCSE 2024 Panel: Interviewing the Teaching Faculty Hiring Process
- **June 6, 2023**: iCSTWS: The Dynamic Evolution of Student Preferences Towards Instructors in a CS1 Course
- **June 5, 2023**: iCSTWS: Guided by Complexity: Automated Code Quality Feedback in CS1
- **August 16, 2022**: iCSTWS: All the Reasons for Frequent Small Assessment
- **May 6, 2022**: WCCCE: How the Pandemic (Permanently) Transformed My Teaching

### Funding

In my previous appointment as a research professor, I received almost $3M in competitive external funding from the NSF and Google, most as PI.

- **2021–2022**: Interactive Code Walkthroughs, $10K from the Grainger College of Engineering through the Strategic Instructional Innovations Program (SIIP). PI with Tiffani Williams and Michael Nowak.
- **2020–2022**: Revising the CS Introductory Programming Sequence, $8.5K from the Grainger College of Engineering through SIIP. Co-PI with Michael Nowak, Carl Evans, Margaret Fleck, Michael Woodley, and Craig Zilles.
- **2017–**: CAREER: Harnessing Implementation Flexibility to Enable Runtime Adaptation, $537K from the National Science Foundation. Sole PI.

### Service

- **2023–:** Chair of the Instructional Computing Committee
- **2023–:** Service on the Grainger College of Engineering New Course and Curricular Review Process Committee
- **2022–2024:** Service on the University General Education Board
- **2022–:** Published a freely-available public version of my CS1 materials at learncs.online
- **2021–2022:** Served as the first teaching faculty chair of the teaching faculty hiring committee
- **2021:** Helped organize the inaugural Illinois Computer Science Summer Teaching Workshop
- **2011–:** Service on departmental committees including Undergraduate Study, Academic Appeals, Broadening Participation in Computing, and others

#### Mentoring

- **2020–** Mentored Assistant Teaching Professor Brad Solomon
- **2020–** Mentored Assistant Teaching Professor Michael Nowak
- **2017–** Mentored dozens of senior staff members for CS 125/4, and supervised over 2000 undergraduate and graduate course staff

### References

1. **Nate Derbinsky**, Teaching Professor, Khoury College of Computer Sciences, Northeastern University (n.derbinsky@northeastern.edu)
1. **Margaret Fleck**, Teaching Professor, University of Illinois (mfleck@illinois.edu)
1. **Cinda Heeren**, Professor of Teaching, University of British Columbia (cheeren@cs.ubc.ca)
1. **Margo Seltzer**, Canada 150 Research Chair and Professor, University of British Columbia (mseltzer@cs.ubc.ca)
1. **Tiffani Williams**, Teaching Professor and Director of Onramp Programs, University of Illinois (tiffani@illinois.edu)
1. **Craig Zilles**, Professor, University of Illinois (zilles@illinois.edu)

### Prior to 2017

Prior to 2017 I led the blue Systems Research Group at the University at Buffalo. My previous CV (https://www.bluegroup.systems/people/challen@buffalo.edu/GeoffreyChallen-CV.pdf) picks up where this one ends.

---

## Teaching Statement

My goal as an educator is to provide everyone with the opportunity to learn the basics of computer science and programming. At the University of Illinois, I have pursued this goal by improving and scaling our first course for majors and students with a deep interest in the subject, which I have taught since Fall 2017. (The course is currently numbered CS 124, but was previously numbered CS 125. To avoid confusion I will use the umbrella term CS1.)

When I began teaching CS1 in Fall 2017, 700 students completed the course, with 50% earning A-range grades and 5% failing. By Fall 2024, over 1,200 students completed the course each fall semester, with 80% earning A-range grades and 2.5% failing. Over 21 terms at Illinois I have taught a total of 15,007 students. Students today get more practice, are better supported, and complete a more challenging project. Grading standards and learning objectives have not changed. Performance gaps between students with and without prior experience and between genders have shrunk significantly, and many CS1 students continue to and succeed in downstream courses. Growth in CS1 has outpaced growth in the major—since Fall 2017 enrollment in CS majors at Illinois has grown by a third, while enrollment in CS1 has nearly doubled. Today 80% of students who enroll in my CS1 course are non-majors, and despite significant differences in academic preparation due to my department's highly-competitive CS admissions, non-majors succeed at similar rates to majors. By supporting student success at scale, my course is helping make computing's remarkable opportunities available to all.

### Chronology of Course Improvements

During my time at Illinois, I have been fortunate to be able to focus my teaching activities entirely on one large course. Taking full advantage of this opportunity, I have been able to complete at least one and frequently several significant course improvement projects each year. Before discussing two important aspects of the design of my course in more detail, I provide an overview of the changes I have made—as my course evolved from a synchronous lecture-based format utilizing high-stakes assessment taught in Java, to an asynchronous lesson-based format utilizing frequent small assessment taught in both Java and Kotlin. Note that these improvements are in addition to the usual tasks required to run a large class—authoring new assessments, maintaining infrastructure, training and managing a large staff, student communication and outreach, dealing with academic integrity, and so on.

As a co-instructor in Fall 2017, I began work on updating and modernizing the assignments and built the course's first continuous autograder. Spring 2018 was the first semester I was responsible for classroom instruction. I migrated away from paper worksheets and to online interactive live coding exercises, supported by the first iteration of a high-performance Java online execution engine that has been used by the course ever since. I also developed support for including small programming exercises on weekly quizzes, released the course's first Android programming project, and created a plagiarism detection pipeline that we continue to use.

In Fall 2018 we began assigning daily programming exercises, and the semester was largely devoted to authoring and deploying the first set of these assignments. Spring 2019 brought new Android programming assignments and assessment infrastructure. By Fall 2019 we were ready to move away from multiple small disconnected programming assignments to a set of connected checkpoints comprising a larger project—providing students the chance to build something more significant, and an experience that more closely mirrors modern software creation. That semester I also completed significant changes to the course infrastructure, migrating to our own private cloud and completing a cloud-native autograder designed to support the new Android programming project.

The COVID-19 pandemic that began in Spring 2020 resulted in a large set of changes to the structure of the course designed to support student success in an online learning environment. I completed a first iteration of our tutoring site over break in Spring 2020, in time to support students during the remainder of that first COVID semester. By Fall 2020 the course was set up online in a completely new format—with daily lessons replacing synchronous lectures, interactive walkthroughs replacing classroom live-coding, and online tutoring replacing in-person office hours. I also created new systems for online quizzing and homework autograding.

By Fall 2021, with evidence that the asynchronous daily lesson model was successful, we began taking advantage of the affordances of this format. I added Kotlin as a language option side-by-side with our existing Java materials, providing students the opportunity to learn a modern multi-paradigm programming language. The Kotlin option also allows students with Java experience the opportunity to reinforce their existing knowledge while also learning something new. Supporting Kotlin required a completely new set of lesson materials, homework, assessments, and project materials and infrastructure. That semester Colleen Lewis also joined as a co-instructor and recorded a complete set of explanations for the existing Java content alongside those I provided in Fall 2020. This allowed students to hear from multiple instructors with different perspectives and mental models. In Spring 2022 I began work on a set of novel debugging exercises, and released our materials publicly at learncs.online. In Fall 2024 I also began teaching CS 199 SOC: Technology and Society, an exploratory seminar examining students' relationship with technology through reading, reflection, and conversation.

In Fall 2022 I fully incorporated those novel debugging challenges into our online materials. I also added new security features to help ensure the integrity of our online quizzes. In 2023 I added profiles of diverse computer scientists to our daily lessons to help students appreciate both the diversity of the field and the many contributions to computer science by diverse individuals. In Fall 2024 I deployed autogenerated testing exercises, providing students with practice writing test suites. More recently, I have introduced quiz retake opportunities to give students additional chances to demonstrate mastery, launched a coaching program to proactively support students who need help with course strategy, and integrated code quality instruction and automated feedback throughout the daily lesson content.

### Frequent Small Assessment

The high rates of student success in my CS1 course are due to many factors. However, I believe that one of the main design choices supporting student success is our use of _frequent small assessment_. In many courses student grades are largely determined by a small set of high-stakes assessments—for example, a few midterms and a final exam, which might together account for 50% or more of a student's grade. In contrast, in my CS1 course the most significant untimed assessment (a one-week project checkpoint) counts for only 4% of a student's grade, and the most significant timed assessment (a one-hour weekly quiz) only counts for 2.5%. I have entirely eliminated high-stakes assessments to reallocate those points toward more-effective frequent small assessment.

Our experience with frequent small assessment has been uniformly positive, and I have cataloged the many and varied ways that this assessment strategy improves my course. First and foremost, students are doing better—with 80% regularly earning A-range grades. This level of student success in CS1 is unusual, and remarkable given that my course covers many topics not always included in an introductory course—including interfaces, functional programming basics, and data structures including linked lists and binary trees. By breaking things down into smaller pieces and requiring that students practice and study regularly, frequent small assessment allows us to both cover more material and graduate students who are uniformly well-prepared for their next CS course. Students don't learn by cramming, and frequent small assessment provides no incentive to pursue this ineffective strategy.

Frequent small assessment also plays a critical role in helping keep students on schedule. Most students who fail my course get into trouble because they get behind. Having a weekly quiz allows us to identify students with knowledge gaps quickly. Students know what they don't know, and can review the material and adjust their study strategies accordingly. My staff performs weekly outreach to students who did poorly on recent assessments. We contact each student directly—both to remind them about our support resources, but also to ensure that they feel _seen_. This is one way that we provide students with the individual attention they might receive in a smaller classroom, but at scale.

Because we assess students frequently, we also have a lot more data about their performance in the class, which allows us to implement flexible and student-friendly grading policies that reduce stress while accounting for the vagaries of life. We provide students with flexibility about when they complete the daily homework, as well as a generous number of drops on both homework and quizzes to accommodate illness and other normal life events. Because the material in CS1 is mostly cumulative, we allow students to raise a quiz score if they do better on the next one—a policy I call catch-up quiz grading, because it encourages students to catch up when they get behind.

While difficult to measure, my impression is that frequent small assessment has resulted in students finding my CS1 course to be easier. I know exactly how much my students have accomplished at the end of the semester. But because the structure provided by frequent small assessment helps students avoid procrastination and generally stay out of trouble, students seem to emerge with the perception that the course was not particularly hard. While this is hard to quantify, I will note that the growth in CS1 since Fall 2017 has not been mirrored in our gentler introductory computer science courses, where enrollments have remained flat or declined while enrollment in my CS1 course has doubled. This suggests the course is appealing effectively to non-majors and calibrated properly for beginners.

### Asynchronous Daily Lesson Format

When the COVID-19 pandemic began, I used the challenge of supporting remote instruction as an opportunity to experiment with a new asynchronous daily lesson model. That change has worked so well that I plan to continue to teach the course in this format.

Prior to Fall 2020, my CS1 course met three times weekly for synchronous instruction. Classroom instruction mixed traditional lecture-based delivery with a heavy complement of live coding exercises integrated directly into the online slides. Participation was graded and students were expected to attend and follow along.

Despite the use of active learning components, the synchronous version of my course suffered from many of the same weaknesses that have been identified in lecture-based courses for decades. No single pace of live instruction is appropriate for a large group—particularly in CS1 which enrolls students with a wide mix of prior experience. Ensuring student participation in classroom activities is difficult. Watching someone else is not only an ineffective way to learn, but can breed overconfidence. Students are naturally reluctant to ask questions in a large classroom, nor is it possible to properly answer all questions asked by students during lecture.

I had prior experience designing and delivering a large course in a fully-flipped format—an introductory course on the Internet that I created at the University at Buffalo. However, that course lacked a well-structured set of assessments to keep students on track and drive engagement, and was ultimately not successful. However, by the time the pandemic started in Spring 2020, I had a well-structured set of CS1 assessments—the daily homework problems and weekly quizzes. With the structure provided by frequent small assessment already in place, I saw an opportunity to create materials that were aligned with the assessments. Materials that would be highly-interactive and encourage student engagement, but allow students to work at their own pace and on their own schedule.

The result was the set of daily lessons that I inaugurated in Fall 2020 and that we have continued to use and update since then. I refactored each week into five daily online lessons. Lessons combine (1) playgrounds, where students can edit, run and experiment with Java and Kotlin code; (2) interactive walkthroughs, which combine audio with an animated editor to support live coding explanations from a community of instructors and course staff, as well as video explanations when appropriate; (3) debugging exercises, where students are challenged to fix small mistakes in code; and (4) practice and homework problems, which engage students in computational challenges. All these components combine to create a highly-interactive student-directed experience, where students are both introduced to new ideas and provided with frequent opportunities to evaluate their understanding of new concepts and reinforce existing skills.

Student success rates using our asynchronous materials have remained strong, even as the course has continued to grow—from 900 students in Fall 2019 (the last pre-pandemic semester), to 1400 students in Fall 2022. Several aspects of the overall design of the course have contributed to its success in this format. One is our use of frequent small assessment, as described above—even more effective now with homework and practice problems more directly integrated alongside the explanatory content. Second, we provide students with online tutoring support from dawn until dusk, to ensure that whenever they are studying, there is a staff member available to help. Together my staff fielded 17,000 questions on our tutoring site in Fall 2022, an average of 14 per student—far more questions than we would be able to field during class. We also see evidence that students are more comfortable asking for private one-on-one tutoring than posting on a public forum.

Together the combination of the asynchronous online format, frequent small assessment, and on-demand tutoring has resulted in a course that is both more successful and more scalable than the previous lecture-based model. While there is the loss of some amount of socialization that can occur in a large lecture, this is more than offset by the increased accessibility of the course, the ability for students to work at their own pace, and the promotion of active and self-directed learning grounded in engagement with the material. As the pandemic has eased, we have reintroduced in-person components into the course, but still find students making heavy use of our online resources. Moving forward, we are exploring ways to create an even stronger sense of course community, particularly through out-of-class activities and engagement opportunities.

### Coaching

In Fall 2024 we launched a coaching program that proactively contacts students in need of support and offers individual course strategy sessions. This program complements our existing dawn-to-dusk online tutoring by identifying students who may be struggling and reaching out to offer personalized guidance on study strategies, time management, and course navigation. Early results suggest that this proactive approach helps students get back on track before small difficulties become larger problems.

---

## Scholarship Statement

To support my goal of giving everyone an opportunity to learn the basics of computer science and programming, I create, deploy, and maintain novel educational technologies—including systems for interactive content delivery, assessment, autograding, online tutoring, plagiarism analysis, state management, and data collection. Each system I have created serves a well-articulated pedagogical goal, and multiple tools are unique to my introductory computer science (CS1) course. I describe several of the most innovative in more detail below.

### Interactive Walkthroughs

Demo: https://www.learncs.online/best#interactive-walkthroughs

Prior to the COVID-19 pandemic, live coding played an important role in classroom instruction in my CS1 course. Live coding allows students to observe and participate in the process of solving computational problems, and allows the instructor to externalize their thought process. It is considered by many to be a best practice when teaching students to program. So when migrating my CS1 materials online to support remote instruction during the pandemic, I knew that I wanted to preserve this component of our instructional approach.

A common way to do this is by posting a video showing the instructor interacting with the code. While workable, this approach has limitations. One of its biggest drawbacks is that the code the instructor is working with is not available to the students throughout the demonstration, since what is delivered to the display is just pixels. The aha moment for me came when I found myself watching a video live coding demonstration and inadvertently clicked on the screen to try to edit the code the presenter was manipulating. Of course, that only caused the video to pause. But I knew that I could create a way to preserve the ability to interact with the code during the live coding explanation.

What emerged from this observation is an instructional component I call an _interactive walkthrough_. An interactive walkthrough presents like a live coding video—students click a button, and then the code starts changing, accompanied by an audio explanation. However, the component is not a video: it's an animated editor, replaying a trace of changes made to the editor during recording by the presenter. Instead of the decontextualized pixels delivered by a live coding video, students have the actual code the instructor is working with in front of them at all times—free for them to experiment with. On my CS1 site, every interactive walkthrough is connected either to our Java and Kotlin playground backend—allowing students to run the code and examine the output—or to our homework autograder—allowing students to submit the code and examine the grading results.

Interactive walkthroughs have become a central feature of our successful online CS1 materials. Each daily lesson contains multiple short interactive walkthroughs, interspersed with text, and other interactive lesson components: playground examples, practice problems, and debugging exercises. Interactive walkthroughs allow us to use video sparingly: only when an explanation requires that we use some non-code component, like a whiteboard or prop.

One of the more exciting opportunities provided by interactive walkthroughs has been the chance to diversify the course's voice. As a white, male, cisgender, heterosexual, able, INTJ computer scientist, I'm very aware of the degree to which I fail to represent the diversity of computer science. While moving away from a lecture model of instruction was prompted by the pandemic, I have embraced the opportunity to invite others into our instructional community and allow my students to hear from a more diverse set of voices. Interactive walkthroughs have proven to be an ideal platform for encouraging contributions from course staff. Most are short, and recording is done entirely _in situ_—right in the browser, with the surrounding lesson material available for context.

Since Fall 2020, almost 300 people have contributed content to my CS1 course by recording at least one interactive walkthrough—including three instructors from two different universities, but mainly drawn from my course staff. Most concepts now have at least two explanations—one from an instructor, and one from a course staff member. Course staff who are mostly former students may lack the deep content knowledge of an instructor, but they can bring a complementary perspective to the material, and may end up providing the analogy or mental model that sticks for a particular student. In addition, our Java materials now almost all have explanations from at least two instructors: myself and Colleen Lewis, who recorded a complete set of walkthroughs for Java in Fall 2021. A student that doesn't quite understand my explanation can review Colleen's, and then possibly one provided by a staff member. I'm also collaborating with Luc Paquette and a graduate student to analyze how students develop preferences between the two instructors. Preliminary results support the hypothesis that having content from multiple instructors available helps support student success in the course, and that students do develop preferences for different instructors in ways both predictable and surprising.

### Homework Autograder and Code Quality Analysis

Demo: https://www.learncs.online/best#homework

Students in my CS1 course benefit from lots and lots of practice. In the past some even requested additional practice problems—and every instructor will remember when a student asks for more work! In addition, as we began asking students to complete programming tasks on our weekly quizzes, it became important to provide a fresh stream of programming challenges for each quiz—updated each semester to avoid the inevitable problems with information sharing about the assessment—but also to continue to build up a library of problems for students to use for practice.

I authored our first set of daily homework problems in Fall 2018. It was a laborious process, usually requiring several hours to author a single exercise. The root of the problem was caused by the need to write test suites for each exercise to allow the autograder to establish correctness. Creating strong test suites is time-consuming, particularly if you aim to test all corner cases and possible failure modalities, and to provide enough inputs to prevent students from "solving" the problem through pure memoization. When authoring test suites for autograding, I frequently found myself embedding small mini-solutions inside my testing code.

This caused me to identify a core difference between software testing and autograding—when using an autograder, the solution is known! This is not normally the case when writing software tests, where only the desired _behavior_ of the solution is known. Instead of maintaining three sources of truth—the description, the reference solution, and the test suites—it should be possible to provide only the description and the solution, and allow a system to generate a testing strategy automatically by observing the solution behavior.

The system we built to support rapid question authoring is called Questioner. Question authors provide a description and a solution. In many cases, Questioner can generate a robust testing suite with only that information—and without requiring a single test case. However, when inputs with special properties are needed, authors can provide input generators. Provided with the solution, Questioner does not only generate a testing strategy—it also validates that its strategy is effective by ensuring that it can reject incorrect submissions. To automatically generate incorrect submissions, Questioner performs source code mutation on the solution. Overall Questioner allows rapid authoring of strong Java and Kotlin programming problems. Since Fall 2020, I have used Questioner to author over 700 programming exercises.

The solution-driven approach also allows Questioner to evaluate a large and growing number of code quality attributes—to assess not only that a submission works, but how good it is. Through deep integration with the Java Virtual Machine, we are now able to efficiently measure multiple aspects of code quality—including style and formatting compliance, cyclomatic complexity, dead code detection, execution efficiency, and memory utilization—all of which are being used to evaluate thousands of student submissions per day.

### Debugging Exercises

Demo: https://www.learncs.online/best#debugging-challenges

Students learning to program will naturally make mistakes. My CS1 course is pro mistakes! We remind students that, if they aren't making mistakes, they aren't learning—an axiom of learning. By making mistakes, students learn to recover from them and gain confidence in their abilities.

Our approach to generating debugging exercises was inspired by Questioner's validation process, which uses source code mutation on the solution to generate incorrect submissions. However, rather than just use the reference solution, our tool uses _all_ the correct submissions for a given question submitted by previous students, resulting in a much larger set of incorrect examples. To complete a debugging exercise a student not only needs to identify and fix the bug, but they must also do so without modifying more of the solution than was modified during the mutation process.

### Testing Exercises

Building on the success of our debugging exercises, in Fall 2024 we deployed autogenerated testing exercises that provide students with practice writing test suites. Writing test suites is not only a critical component of software creation, but provides students the opportunity to demonstrate their understanding of a problem and learn to think defensively by anticipating corner cases and problematic inputs. Using a similar mutation-based approach to our debugging exercises, we generate testing challenges that require students to write tests that can distinguish correct implementations from subtly incorrect ones.

---

## Service Statement

During my time at Illinois I have focused my service activities on opportunities to improve and support teaching and learning both inside and outside the university. I have served on departmental committees (undergraduate studies, broadening participation, technology facilities and services, teaching faculty recruiting, and instructional computing) and engaged in university service (Academic Senate, General Education Board, and the Grainger College of Engineering New Course and Curricular Review Process Committee). I have also led new initiatives, including making significant changes to the undergraduate curriculum, inaugurating a new teaching faculty workshop, updating and improving our teaching faculty hiring process, and designing a new course on technology and society. I also engage in advocacy on behalf of teaching and teaching faculty, participate actively in an online community of practice with other computer science educators, and have made my CS1 materials publicly available. I describe some of my more significant service contributions below.

### Revising the Undergraduate Core Programming Curriculum

When I arrived in Fall 2017 and began teaching CS1, it quickly became clear that we had a problem in our early curriculum. Several years before I arrived, students would begin in CS1, where they would gain some programming experience—some for the first time. They would then spend a second semester in our discrete structures course learning the basics of proof-based mathematics. Both these courses prepared them for a third-semester course on data structures (DS), which leveraged both their programming and mathematical preparation.

However, it had been noted that our majors were struggling with programming tasks when they reached DS. The problem was the long gap between gaining preliminary programming experience in CS1 in their first semester and their arrival in DS in their third semester. Programming is a skill. Without practice, students were getting rusty.

The solution in place when I arrived was a second-semester programming class taken alongside discrete structures. Unfortunately, this fix had a flaw—the second-semester programming course was only offered to students majoring in computer science. But a large and growing number of students coming through our early programming curriculum are non-majors. As a result, the new second-semester programming course was failing to meet its design goals.

I led a team of instructors that identified and corrected this problem, resulting in a redesigned set of early programming courses taken by all students—both majors and non-majors. I drafted design specifications for the new courses, prepared justifications and other materials, and supported the change through the many rounds of review and approvals required. After a multi-year approval process, the new curriculum went live for students entering in Fall 2021.

### Improving Teaching Faculty Hiring

After serving on the teaching faculty hiring committee for several years, in 2021 I was the first teaching faculty to chair our teaching faculty search. As chair, I improved our process to better attract and recruit excellent candidates. I rewrote our ad and other promotional materials to highlight the many ways the department supports teaching faculty.

I also made significant changes to our interview process. Previously, our interview comprised a live teaching demonstration. However, this format has multiple weaknesses. To address these concerns, I redesigned the interview talk as a presentation on effective pedagogy. This allows candidates to provide us with a holistic overview of how they teach—addressing things like course format, assessment, materials, grade design, calibration, community, collaboration, student motivation, scaling, support structures, data collection and analysis, and creating an equitable and inclusive learning environment.

### Publicly-Available CS1 Materials

In Spring 2022 I began the process of making our Java and Kotlin CS1 material freely available at learncs.online. My goal is to support independent learners by providing access to all of the same interactive components that have made my CS1 course so successful: 900 interactive playgrounds containing editable and executable code examples, 2,600 interactive walkthroughs provided by almost 300 instructors explaining core computer science concepts, almost 300 programming problems to test comprehension, and dozens of debugging exercises.

Over its first year of operation, learncs.online has supported thousands of independent learners. It is also beginning to generate outreach opportunities, including a pilot collaboration with another education institution and use by outreach programs for diverse high school students.

### Other Activities

**Course Design:** In 2024 I designed and deployed CS 199 SOC: Technology and Society, an exploratory seminar examining students' relationship with technology through reading, reflection, and conversation.

**Summer Teaching Workshop:** Together with several teaching faculty colleagues, I helped launch the Illinois Computer Science Summer Teaching Workshop. Now in its fifth year, the teaching workshop continues to provide a welcoming space for open discussion on innovation and best practices among college computer science educators.

**Academic Data Analysis:** We collect a lot of data in my course, and this has allowed me to support departmental academic data analysis, including deriving program retention statistics and compiling data on representation from diverse groups.

**Advocacy:** Over the past several years I have begun to post essays on teaching and other related topics on my website. A set of essays on evaluating teaching faculty positions generated significant interest and was cited by several recent applicants as a reason they decided to apply to teach at the University of Illinois.

**Mentoring:** I am fortunate to have the opportunity to work closely each semester with a small number of undergraduates and graduate students selected to help lead my CS1 course. Since 2017, over 2,200 students have served as members of the CS 125/4 course staff.

**Community of Practice:** Since 2021 I have been an active participant in an online community of practice with over 100 other computer science educators from dozens of institutions across the world.

---

## Projects

**I write code that helps students learn.**

I create and maintain a variety of software tools to support my courses. Most of my projects are published on GitHub, and many are publicly deployed and freely available for educators and students to use and extend.

### learncs.online: Learn to Program Online

learncs.online is the freely-available version of the materials developed to support CS 124—my CS1 course at Illinois.

learncs.online provides public access to many of the same novel features that have helped make CS 124 so successful:

- 61 daily lessons introducing programming and computer science concepts in both Java and Kotlin
- 902 runnable and editable playground examples
- 2,540 interactive walkthroughs from 264 instructors
- 132 homework problems providing both correctness and code quality feedback
- novel debugging challenges to train students to fix mistakes

Demo: https://learncs.online/
Credits: Hundreds of course staff have contributed content to learncs.online, creating the first crowdsourced CS1 course.

### Interactive Code Walkthroughs

One of the most distinctive features of the learncs.online and CS 124 materials is their use of _interactive walkthroughs_.

This novel component combines the best features of recorded live coding—being able to watch exactly what the instructor is doing and listen to their explanation—while still maintaining the interactive features of a playground. Because the interactive walkthrough is an animated editor and _not_ a video, students can pause at any point and edit or execute the code.

Interactive walkthroughs are also recorded _in-situ_ directly on the page where they are viewed, providing authors with awareness of how that explanation is used within the context of the surrounding information. By lowering the barrier to providing this kind of content, we have been able to incorporate contributions from hundreds of CS 124 course staff, significantly diversifying the course's voice.

Demo: https://www.learncs.online/best#interactive-walkthroughs

### Rapid and Accurate Programming Exercise Authoring and Autograding

Students learning to program benefit from practice. But the traditional approach to writing autograded programming questions by authoring test suites is slow, inaccurate, and ineffective.

We created a system called Questioner to address these weaknesses. Questioner leverages a key difference between typical software testing and autograding—when grading, the solution is known! Instead of requiring instructors write test suites, Questioner has them provide a solution and automates as much of the rest of the process as possible. Since Fall 2020 I have used Questioner to author over 700 programming exercises.

Demo: https://www.learncs.online/best#homework, https://beyondgrader.com
GitHub: Jenisol solution analysis library, Questioner full system integration

### Code Quality Autograding

An oft-cited weakness of autograding is that students don't get feedback on the _quality_ of their code. Our goal is to provide students with automated code _quality_ feedback—in real time, on every submission, and with no human input.

Currently, through a combination of source and bytecode analysis, we are able to automatically evaluate multiple code quality metrics—including linting (format checking), cyclomatic complexity, runtime and memory efficiency, source line counts, dead code detection, and recursion and feature analysis.

Demo: https://www.learncs.online/best#code-quality, https://beyondgrader.com

### Autogenerated Debugging Exercises

Beginning programmers make mistakes, and learning how to fix those mistakes is critical to their development as successful and confident programmers. To provide students more practice with debugging we created a tool that autogenerates incorrect submissions to our programming exercises using source-level mutation.

When a student begins work on a debugging challenge, they are presented with an incorrect submission and asked to fix it. To do so, they must change no more lines than were altered by the mutation! This prevents students from simply replacing the entire incorrect submission with known-correct code, forcing them to provide a minimal fix.

Demo: https://www.learncs.online/best#debugging-challenges

### Online Tutoring Site

When the pandemic began in Spring 2020, I rapidly created an online tutoring platform allowing staff to efficiently provide students with remote assistance. We have continued to use a variant of this tool since Spring 2020, and it has connected thousands of students with course staff for tutoring.

### Speedy JVM Execution and Analysis (Jeed)

Jeed is the speedy JVM execution and analysis toolkit. Jeed's primary purpose is to enable fast and safe execution of untrusted Java and Kotlin code. Jeed runs untrusted code in a secure JVM sandbox 1000 times faster than approaches that rely on containerization. This performance boost makes it possible to support a large amount of interactive use using a small amount of server resources. Jeed has been in production use since 2019.

Demo: https://www.learncs.online/best#playgrounds, or https://www.jeed.run/
GitHub: Jeed project repository

---

## Bio

### Short Bio

Geoffrey Challen is a Teaching Professor at the University of Illinois. He teaches introductory programming and computer science to thousands of students each year, and creates novel software to support his courses and materials. Geoffrey publishes essays on teaching and technology at geoffreychallen.com, where you can also find out more about his work.

### Longer Bio

See the About section below.

---

## About

Hi, I'm Geoff! I love to teach, and I love to code. I teach students to code, and I write code that helps them learn. My goal is to teach as many students as possible. I do this by creating interactive learning environments that scale.

I post essays on teaching, technology, and the overlap between the two. I try to keep my essays on teaching accessible to teachers who don't program, and my essays on technology interesting to programmers who don't teach.

### Teaching

I'm currently teaching faculty at the University of Illinois. I teach our first course on computer science for majors and students with a deep interest in the subject. You might call it CS1. We call it CS 124.

My course enrolls several thousand students per year. Almost its entire tech stack has been created specifically to support and scale the course learning objectives—including custom systems for interactive instruction, homework authoring and autograding, quiz design and delivery, student support, and large-assignment autograding. I get to build most of these things, and it's huge fun.

Both content and assessments are structured to provide students with daily practice and reinforcement, comprising daily lessons and homework problems, weekly proctored quizzes incorporating multiple programming questions, and a longer multi-part programming project.

After fifteen weeks, students who enter my course with no prior programming experience can successfully complete moderately-difficult programming problems under proctored conditions—such as simple class design, binary tree and linked list operations, and sorting algorithms such as Quicksort partition. They have also completed an Android programming project, demonstrating their ability to successfully work in an unfamiliar and challenging environment and correctly modify and extend existing source code.

I am also active in working to improve the curriculum surrounding my course. I led a team of teaching faculty colleagues in a successful effort to redesign our introductory programming sequence.

In response to the 2020 COVID-19 pandemic I completely redesigned my course in an asynchronous online format. The benefits have been enormous. The online format has allowed us to more effectively engage students each day, improved accessibility by allowing the course to scale further, and produced materials that are more maintainable and a course that is more manageable.

### Coding

I love to program! Both because it allows me to create incredible things, and to create those things beautifully. Programming can and should be fun.

My programming projects are almost entirely in support of my CS1 course. Most of them fall into one of two categories—tools to help efficiently generate content or assessments, and ways to create more interactive engaging learning environments.

I maintain both frontend and backend systems—both interactive course websites and the microservices that support them. I use React TypeScript and the frameworks Gatsby and NextJS for my frontend websites and a mix of Kotlin and TypeScript for my backend servers.

At present Kotlin is my programming language of choice. It supports many different programming paradigms without being overly opinionated, allowing you to write an effective mix of imperative, object-oriented, and functional code.

I deploy containerized backend services to a private cloud managed using Kubernetes.

### Personal

I was born Geoffrey Werner-Allen. I used that name professionally until I married Suzanna Chapman, and we became the Challens.

My wife and I share a beautiful old house in Champaign, Illinois, with a sweet cat Xyz, an even sweeter dog Gracie, and memories of our former love dog Chuchu. For me programming is a hobby as well as a profession. But I also enjoy cooking and eating, exercise, reading, music, and ultimate frisbee.
